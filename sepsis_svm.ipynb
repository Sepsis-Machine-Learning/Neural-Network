{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalizeData(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "train = pd.read_csv(\"../data/setB_train.psv\", sep='|')\n",
    "test = pd.read_csv(\"../data/setB_test.psv\", sep='|')\n",
    "\n",
    "# Visualize missing values as a matrix\n",
    "#msno.matrix(train)\n",
    "#msno.matrix(test)\n",
    "#msno.matrix(pd.read_csv(\"../data/setB_train.psv\", sep='|'))\n",
    "#msno.matrix(pd.read_csv(\"../data/setB_test.psv\", sep='|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#msno.bar(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#msno.bar(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/setA_train.psv\", sep='|')\n",
    "#print(train.shape)\n",
    "#print(train)\n",
    "#drop columns which have more than 94% NaN's by index\n",
    "#cols = [7,14,16,20,22,26,27,32]\n",
    "cols = [7,20,27]\n",
    "train.HospAdmTime = -1 * train.HospAdmTime\n",
    "train=train.drop(train.columns[cols],axis=1)\n",
    "#replace NaN with mean\n",
    "train[np.isnan(train)] = -99\n",
    "#train=train.fillna(train.mean())\n",
    "\n",
    "train=train.values\n",
    "test = pd.read_csv(\"../data/setA_test.psv\", sep='|')\n",
    "#train, test = train_test_split(train, test_size=0.2)\n",
    "#print(train.shape)\n",
    "#print(train)\n",
    "test.HospAdmTime = -1 * test.HospAdmTime\n",
    "test=test.drop(test.columns[cols],axis=1)\n",
    "#replace NaN with mean\n",
    "test[np.isnan(test)] = -99\n",
    "#test=test.fillna(test.mean())\n",
    "test=test.values\n",
    " \n",
    "#train, test = train_test_split(train, test_size=0.2)\n",
    "#print(train.shape)\n",
    "#print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02522051 0.02673649 0.         ... 0.         0.01364802 0.01998346]\n",
      " [0.02742558 0.02556505 0.         ... 0.         0.01364802 0.02039691]\n",
      " [0.02852811 0.02687431 0.         ... 0.01364388 0.01365077 0.01943219]\n",
      " ...\n",
      " [0.03293826 0.02701213 0.         ... 0.         0.01364802 0.01819184]\n",
      " [0.03018192 0.02687431 0.         ... 0.         0.01364802 0.01832966]\n",
      " [0.02949283 0.02673649 0.         ... 0.         0.01364802 0.01846748]]\n",
      "[0. 0. 0. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "x_train_raw = train[:, :-1] # for all but last column\n",
    "n_rows, n_cols = x_train_raw.shape\n",
    "\n",
    "x_test_raw = test[:, :-1]\n",
    "y_train = train[:, -1]  # for last column\n",
    "y_test = test[:, -1]  # for last column\n",
    "x_train = NormalizeData(x_train_raw)\n",
    "x_test = NormalizeData(x_test_raw)\n",
    "#x_train = x_train_raw\n",
    "#x_test = x_test_raw\n",
    "print(x_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=2, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "#svclassifier = SVC(kernel='linear', probability=True) # in default probability=false; proba data will be used for ROC AUC\n",
    "#svclassifier = SVC(kernel='linear') # in default probability=false; use it to save run time!\n",
    "svclassifier = SVC(kernel='rbf', C=2) # Gaussian kernel\n",
    "#svclassifier = SVC(kernel='poly', degree=2)\n",
    "svclassifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2294 1056]\n",
      " [ 450 7274]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.94      0.91      7724\n",
      "         1.0       0.84      0.68      0.75      3350\n",
      "\n",
      "    accuracy                           0.86     11074\n",
      "   macro avg       0.85      0.81      0.83     11074\n",
      "weighted avg       0.86      0.86      0.86     11074\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = svclassifier.predict(x_test)\n",
    "#y_proba = svclassifier.predict_proba(x_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred, labels=[1, 0]))\n",
    "print(classification_report(y_test,y_pred))\n",
    "#print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.set_printoptions(threshold=np.inf)\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y_proba[:5])\n",
    "#y_probs = y_proba[:,0]\n",
    "#y_probs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.864006\n",
      "Precision: 0.836006\n",
      "Recall: 0.684776\n",
      "F1 score: 0.752872\n",
      "Cohens kappa: 0.660338\n",
      "Confusion_matrix:\n",
      "                    TrueP FalseN\n",
      "                    FalseP TrueN\n",
      "[[2294 1056]\n",
      " [ 450 7274]]\n"
     ]
    }
   ],
   "source": [
    "#y_probs = y_proba[:,0]\n",
    "y_classes = y_pred\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, y_classes)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, y_classes)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, y_classes)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, y_classes)\n",
    "print('F1 score: %f' % f1)\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_test, y_classes)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "#auc = roc_auc_score(y_test, y_probs)\n",
    "#print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "print('Confusion_matrix:')\n",
    "print('                    TrueP FalseN')\n",
    "print('                    FalseP TrueN')\n",
    "#labels must be specified as [1,0]. Without it, confusion_matrix\n",
    "#will report negative on the 1st row then positives on the 2nd row\n",
    "#note: predictions are in columns and actual values in rows !!\n",
    "matrix = confusion_matrix(y_test, y_classes, labels=[1, 0])\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
